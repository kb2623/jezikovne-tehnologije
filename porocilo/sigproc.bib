@inproceedings{Chen:2012:DOL:2411131.2411739,
 author = {Chen, Ying and Zhou, Yilu and Zhu, Sencun and Xu, Heng},
 title = {Detecting Offensive Language in Social Media to Protect Adolescent Online Safety},
 booktitle = {Proceedings of the 2012 ASE/IEEE International Conference on Social Computing and 2012 ASE/IEEE International Conference on Privacy, Security, Risk and Trust},
 series = {SOCIALCOM-PASSAT '12},
 year = {2012},
 isbn = {978-0-7695-4848-7},
 pages = {71--80},
 numpages = {10},
 url = {http://dx.doi.org/10.1109/SocialCom-PASSAT.2012.55},
 doi = {10.1109/SocialCom-PASSAT.2012.55},
 acmid = {2411739},
 publisher = {IEEE Computer Society},
 address = {Washington, DC, USA},
 keywords = {cyberbullying, adolescent safety, offensive languages, social media},
}

@Article{Burnap2016,
author="Burnap, Pete
and Williams, Matthew L.",
title="Us and them: identifying cyber hate on Twitter across multiple protected characteristics",
journal="EPJ Data Science",
year="2016",
volume="5",
number="1",
pages="11",
abstract="Hateful and antagonistic content published and propagated via the World Wide Web has the potential to cause harm and suffering on an individual basis, and lead to social tension and disorder beyond cyber space. Despite new legislation aimed at prosecuting those who misuse new forms of communication to post threatening, harassing, or grossly offensive language - or cyber hate - and the fact large social media companies have committed to protecting their users from harm, it goes largely unpunished due to difficulties in policing online public spaces. To support the automatic detection of cyber hate online, specifically on Twitter, we build multiple individual models to classify cyber hate for a range of protected characteristics including race, disability and sexual orientation. We use text parsing to extract typed dependencies, which represent syntactic and grammatical relationships between words, and are shown to capture `othering' language - consistently improving machine classification for different types of cyber hate beyond the use of a Bag of Words and known hateful terms. Furthermore, we build a data-driven blended model of cyber hate to improve classification where more than one protected characteristic may be attacked (e.g. race and sexual orientation), contributing to the nascent study of intersectionality in hate crime.",
issn="2193-1127",
doi="10.1140/epjds/s13688-016-0072-6",
url="http://dx.doi.org/10.1140/epjds/s13688-016-0072-6"
}

@article {POI3:POI385,
author = {Burnap, Pete and Williams, Matthew L.},
title = {Cyber Hate Speech on Twitter: An Application of Machine Classification and Statistical Modeling for Policy and Decision Making},
journal = {Policy & Internet},
volume = {7},
number = {2},
issn = {1944-2866},
url = {http://dx.doi.org/10.1002/poi3.85},
doi = {10.1002/poi3.85},
pages = {223--242},
keywords = {Twitter, hate speech, Internet, policy, machine classification, statistical modeling, cyber hate, ensemble classifier},
year = {2015},
}
