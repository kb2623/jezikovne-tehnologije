{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'svmutil'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cf2dfc0a680c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msvmutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'svmutil'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import re\n",
    "from sklearn import svm\n",
    "from svmutil import *\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from random import shuffle\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_znacilke(komentarji, vse_besede):\n",
    "    \n",
    "    # Metoda vrne značilke, ki se pojavljajo v posameznem komentarju\n",
    "    \n",
    "    urejene_besede = sorted(vse_besede)\n",
    "    znacilke = []\n",
    "    \n",
    "    for komentar in komentarji:\n",
    "        word_map = {}\n",
    "        \n",
    "        # Za vsak komentar nastavimo pojavitve vseh besed na 0\n",
    "        for beseda in urejene_besede:\n",
    "            word_map[beseda] = 0\n",
    "        \n",
    "        # Za vsako besedo (del komentarja), ki se pojavi, nastavimo pojavitev na 1\n",
    "        for del_komentarja in komentar:\n",
    "            if(del_komentarja in word_map):\n",
    "                word_map[del_komentarja] = 1\n",
    "              \n",
    "        # Pojavitev besed trenutnega komentarja dodamo v skupne pojavitve\n",
    "        values = list(word_map.values())\n",
    "        znacilke.append(values)\n",
    "\n",
    "    return znacilke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_znacilke_oznake(komentarji, vse_besede):\n",
    "\n",
    "    # Metoda vrne slovar z tipi komentarji in značilkami, ki se pojavljajo v posameznem komentarju\n",
    "    \n",
    "    urejene_besede = sorted(vse_besede)\n",
    "    znacilke = []\n",
    "    oznake = []\n",
    "    \n",
    "    for komentar in komentarji:\n",
    "        oznaka = 0\n",
    "        word_map = {}\n",
    "        \n",
    "        # Za vsak komentar nastavimo pojavitve vseh besed na 0\n",
    "        for beseda in urejene_besede:\n",
    "            word_map[beseda] = 0\n",
    "        \n",
    "        if len(komentar) > 1:\n",
    "            # Komentar razbijemo na 2 dela -> tip komentarja in sam komentar\n",
    "            besedilo_komentarja = komentar[0]\n",
    "            zaljivost_komentarja = komentar[1]\n",
    "        \n",
    "            # Za vsako besedo (del komentarja), ki se pojavi, nastavimo pojavitev na 1\n",
    "            for del_komentarja in besedilo_komentarja:\n",
    "                word_map[del_komentarja] = 1\n",
    "            \n",
    "            # Pojavitev besed trenutnega komentarja dodamo v skupne pojavitve\n",
    "            values = list(word_map.values())\n",
    "            znacilke.append(values)\n",
    "\n",
    "            # Preverimo tip komentarja\n",
    "            if zaljivost_komentarja == 0:\n",
    "                oznaka = 0\n",
    "            elif zaljivost_komentarja == 1:\n",
    "                oznaka = 1\n",
    "\n",
    "            # Dodamo med vse tipe komentarjev\n",
    "            oznake.append(oznaka)\n",
    "        \n",
    "    return {'pojavitev_besed' : znacilke, 'oznake':oznake}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preuredi_besedilo(tekst):\n",
    "\n",
    "    # Metoda vrne prečiščen tekst\n",
    "\n",
    "    tekst = tekst.lower()\n",
    "    # Odstrani URL-je\n",
    "    tekst = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','', tekst)\n",
    "    # Odstrani NEWLINE_TOKEN\n",
    "    tekst = re.sub('newline_token', '', tekst)\n",
    "    tekst = re.sub('newline', '', tekst)\n",
    "    tekst = re.sub('tokennewline', '', tekst)\n",
    "    # Odstrani TAB_TOKEN\n",
    "    tekst = re.sub('tab_token', '', tekst)\n",
    "    # Pretvori `` to \"\n",
    "    tekst = re.sub('``', '\"', tekst)\n",
    "    # Pretvori ` to '\n",
    "    tekst = re.sub('`', '\\'', tekst)\n",
    "    # Odstrani =\n",
    "    tekst = re.sub('=', '', tekst)\n",
    "    # Odstrani \\n\n",
    "    tekst = re.sub('\\n', '', tekst)\n",
    "    # Odstrani :\n",
    "    tekst = re.sub(':', '', tekst)\n",
    "    # Odstrani odvečne presledke\n",
    "    tekst = re.sub('[\\s]+', ' ', tekst)\n",
    "    # Odstrani začetne/končnne presledke\n",
    "    tekst = tekst.strip()\n",
    "    # Odstrani narekovaje\n",
    "    tekst = tekst.strip('\\'\"')\n",
    "\n",
    "    return tekst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_posamezne_besede(komentar, stopwords):\n",
    "    \n",
    "    # Metoda odstrani presledke, končnice in vrne posamezne besede\n",
    "\n",
    "    # Odstranimo nepotrebne whitespace in spremenimo v male črke\n",
    "    komentar = preuredi_besedilo(komentar)\n",
    "    komentar = \" \".join(re.split(\"[^a-zA-Z]*\", komentar.lower())).strip()\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    besede = []\n",
    "    \n",
    "    # Razbijemo na besede in porežeo končnice\n",
    "    for beseda in komentar.split():\n",
    "        if not beseda in stopwords:\n",
    "            try:\n",
    "                besede.append(stemmer.stem(beseda))\n",
    "            except(IndexError):\n",
    "                besede.append(beseda)\n",
    "\n",
    "    return besede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ngram(komentar, min_n, max_n, stopwords):\n",
    "    \n",
    "    # Metoda vrne n-grame za določen tweet\n",
    "    \n",
    "    komentar = preuredi_besedilo(komentar)\n",
    "    komentar = \" \".join(re.split(\"[^a-zA-Z]*\", komentar.lower())).strip()\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    ngram = []\n",
    "    besede = komentar.split()\n",
    "    \n",
    "    for k in range(min_n, max_n + 1):\n",
    "        for i in range(0, len(besede) - k):\n",
    "            posamezni_ngram = \"\"\n",
    "            \n",
    "            sw_stevec = 0\n",
    "            for j in range(0, k + sw_stevec):\n",
    "                if not besede[i + j] in stopwords:\n",
    "                    posamezni_ngram += stemmer.stem(besede[i + j])\n",
    "                    if j < max_n:\n",
    "                        posamezni_ngram += \" \"\n",
    "                else:\n",
    "                    sw_stevec += 1\n",
    "            \n",
    "            ngram.append(posamezni_ngram)\n",
    "    \n",
    "    return ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(tekst, test_tekst, algoritem):\n",
    "\n",
    "    # Pridobitev stop words (besed brez pomena)\n",
    "    # nltk.download()\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "    komentarji = []\n",
    "    besede = []\n",
    "\n",
    "    for vrstica in tekst:\n",
    "        # Vrstico razbijemo na 2 dela - tip komentarja in sam komentar\n",
    "        vrstica = vrstica.split(\"\\t\")\n",
    "        tip_zaljivosti = int(vrstica[0])\n",
    "        komentar = vrstica[1]\n",
    "        # Sam komentar uredimo in odstranimo nepotrebne znake\n",
    "        # Pridobimo posamezne besede (s pomenom in brez končnic)\n",
    "        \n",
    "        if algoritem == \"BOW\":\n",
    "            besede_komentarja = get_posamezne_besede(komentar, stopwords)\n",
    "        elif algoritem == \"NGRAM\":\n",
    "            # besede_komentarja = get_ngram(komentar, 1, 1, stopwords)\n",
    "            besede_komentarja = get_ngram(komentar, 1, 3, stopwords)\n",
    "        \n",
    "        # Ustvarimo nove - urejene komentarje in dodamo tip komentarja\n",
    "        komentarji.append((besede_komentarja, tip_zaljivosti))\n",
    "        # V slovar vseh besed dodamo besede trenutno obravnavanega slovarja\n",
    "        for beseda in besede_komentarja:\n",
    "            besede.append(beseda)\n",
    "\n",
    "    # Učenje na podlagi učne množice\n",
    "    znacilke_oznake = get_znacilke_oznake(komentarji, besede)    \n",
    "    problem = svm_problem(znacilke_oznake['oznake'], znacilke_oznake['pojavitev_besed'])\n",
    "    param = svm_parameter('-s 1 -b 1')\n",
    "    param.kernel_type = LINEAR #LINEAR RBF SIGMOID POLY\n",
    "    ucenec = svm_train(problem, param)\n",
    "    # svm_save_model('classifier.txt', classifier)\n",
    "    \n",
    "    test_besede = []\n",
    "    # v test_zaljivosti hranimo podatke o pravih klasifikacijah - za kasnejše preverjanje\n",
    "    test_zaljivost = []\n",
    "\n",
    "    for vrstica in test_tekst:\n",
    "        # Vrstico razbijemo na 2 dela - tip komentarja in sam komentar\n",
    "        vrstica = vrstica.split(\"\\t\")\n",
    "        # Vrsto komentarja si shranimo za kasnejše preverjanje\n",
    "        tip_zaljivosti = int(vrstica[0])\n",
    "        # Komentar obdelamo, pridobimo posamezne besede in jih dodamo v slovar\n",
    "        komentar = vrstica[1]\n",
    "        # test_posamezne_besede = [beseda.lower() for beseda in komentar.split()]\n",
    "        \n",
    "        if algoritem == \"BOW\":\n",
    "            test_besede_komentarja = get_posamezne_besede(komentar, stopwords)\n",
    "        elif algoritem == \"NGRAM\":\n",
    "            # test_besede_komentarja = get_ngram(komentar, 1, 1, stopwords)\n",
    "            test_besede_komentarja = get_ngram(komentar, 1, 3, stopwords)\n",
    "        \n",
    "        test_besede.append(test_besede_komentarja)\n",
    "        test_zaljivost.append(tip_zaljivosti)\n",
    "\n",
    "    print \"\\n\" + algoritem\n",
    "        \n",
    "    # Pridobitev znacilk    \n",
    "    test_znacilke = get_znacilke(test_besede, besede)\n",
    "    predvidevana_zaljivost, a, b = \n",
    "        svm_predict(test_zaljivost, test_znacilke, ucenec, options = \"-b 1\")\n",
    "    \n",
    "    print(classification_report(test_zaljivost, predvidevana_zaljivost))\n",
    "    \n",
    "    '''# Skupaj - st testnih podatkov, pravilni - pravilno klasificirani\n",
    "    # napacno - podatki ki bi morali biti klasificirani kot hate speech pa niso\n",
    "    # stevec - števec za array\n",
    "    skupaj, pravilni, napacni, stevec = 0, 0, 0, 0\n",
    "    natancnost, priklic = 0.0, 0.0\n",
    "    \n",
    "    # Preštejemo število pravilno klasificiranih komentarjev\n",
    "    for zaljivost in test_zaljivost:\n",
    "        oznaka = int(predvidevana_zaljivost[stevec])\n",
    "        if(oznaka == int(zaljivost)):\n",
    "            pravilni += 1\n",
    "        elif (oznaka != int(zaljivost) & zaljivost == 1)\n",
    "            napacni += 1\n",
    "        skupaj += 1\n",
    "        stevec += 1\n",
    "    \n",
    "    natancnost = (float(pravilni) / skupaj) * 100\n",
    "    priklic = (float(pravilni / (pravilni + napacni)))'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Pridobitev vseh podatkov\n",
    "    datoteka = open('data/comments.txt')\n",
    "    tekst = datoteka.readlines()[1:]\n",
    "    datoteka.close()\n",
    "    \n",
    "    shuffle(tekst)\n",
    "    \n",
    "    st_komentarjev = len(tekst)\n",
    "    deli = st_komentarjev * 100 / 70\n",
    "    \n",
    "    # Pridobitev učnih podatkov\n",
    "    # ucna_datoteka = open('data/comments_sample.txt')\n",
    "    # ucna_tekst = ucna_datoteka.readlines()[1:]\n",
    "    # ucna_datoteka.close()\n",
    "    \n",
    "    ucna_tekst = tekst[1:5000]\n",
    "    \n",
    "    # Pridobitev testnih podatkov\n",
    "    # test_datoteka = open(\"data/test_comments.txt\")\n",
    "    # test_tekst = test_datoteka.readlines()[1:]\n",
    "    # test_datoteka.close()\n",
    "    \n",
    "    test_tekst = tekst[5000:6000]\n",
    "    \n",
    "    run(ucna_tekst, test_tekst, \"BOW\")\n",
    "    run(ucna_tekst, test_tekst, \"NGRAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kako učimo na učni množici:\n",
    "    1. Preberemo učno datoteko s komentarji (tip komentarja in tekst)\n",
    "    2. Pridobimo stopworde (besede brez pomena)\n",
    "    3. Vsako vrstico razdelimo na tip in sam komentar:\n",
    "        1. Komentar uredimo (odstranimo odvečne znake, odstranimo končnice, pripravimo na procesiranje)\n",
    "        2. Pridobimo besede v posameznem komentarju, dodamo jih v 'slovar besed'\n",
    "    4. Slovar besed in komentarje obdelamo:\n",
    "        1. V slovarju za vsak komentar shranimo tip komentarja in besede ki se oz. \n",
    "        se ne pojavljajo v komentarju\n",
    "        2. Besede, ki se pojavijo v slovarju in v komentarju so označene z 1, ostale z 0.\n",
    "\n",
    "Kako testiramo testno množico:\n",
    "    1. Preberemo testno datoteko s komentarji (top komentarja in tekst)\n",
    "    2. Pridobimo stopworde (besede brez pomena)\n",
    "    3. Vsako vrstico razbijemo na tip in sam komentar:\n",
    "        1. Tip si shranimo za kasnejše preverjanje uspešnosti klasifikacije komentarja\n",
    "        2. Komentar uredimo (odstranimo odvečne znake, odstranimo končnice, pripravimo na procesiranje)\n",
    "        3. Pridobimo besede v posameznem komentarju, dodamo jih v 'slovar testnih besed'\n",
    "    4. Slovar besed in testnih komentarjev obdelamo:\n",
    "        1. Pridobimo informacije o besedah ki se oz. se ne pojavljaju v komentarju\n",
    "        2. Besede, ki se pojavijo v slovarju in komentarju so označene z 1, ostale z 0.\n",
    "    5. Komentarjem na podlagi pojavljanja besed določimo tip (svm_predict)\n",
    "    6. Izračunamo verjetnost (pravilno določeni tipi / vsi določeni tipi)*100\n",
    "   \n",
    "    \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
