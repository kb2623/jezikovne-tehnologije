{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "from random import shuffle\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "import nltk.corpus\n",
    "from nltk import ngrams, FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_znacilke(komentarji, vse_besede):    \n",
    "    '''\n",
    "    Metoda vrne značilke, ki se pojavljajo v posameznem komentarju\n",
    "    '''    \n",
    "    urejene_besede = sorted(vse_besede)\n",
    "    znacilke = []    \n",
    "    for komentar in komentarji:\n",
    "        word_map = {}\n",
    "        for beseda in urejene_besede:\n",
    "            word_map[beseda] = 0\n",
    "        for del_komentarja in komentar:\n",
    "            if(del_komentarja in word_map):\n",
    "                word_map[del_komentarja] = 1\n",
    "        values = list(word_map.values())\n",
    "        znacilke.append(values)\n",
    "    return znacilke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_znacilke_oznake(komentarji, vse_besede):\n",
    "    '''\n",
    "    Metoda vrne slovar z tipi komentarji in značilkami, ki se pojavljajo v posameznem komentarju\n",
    "    '''    \n",
    "    urejene_besede = sorted(vse_besede)\n",
    "    znacilke = []\n",
    "    oznake = []    \n",
    "    for komentar in komentarji:\n",
    "        oznaka = 0\n",
    "        word_map = {}\n",
    "        for beseda in urejene_besede:\n",
    "            word_map[beseda] = 0        \n",
    "        if len(komentar) > 1:\n",
    "            besedilo_komentarja = komentar[0]\n",
    "            zaljivost_komentarja = komentar[1]\n",
    "            for del_komentarja in besedilo_komentarja:\n",
    "                word_map[del_komentarja] = 1\n",
    "            values = list(word_map.values())\n",
    "            znacilke.append(values)\n",
    "            if zaljivost_komentarja == 0:\n",
    "                oznaka = 0\n",
    "            elif zaljivost_komentarja == 1:\n",
    "                oznaka = 1\n",
    "            oznake.append(oznaka)        \n",
    "    return {'pojavitev_besed' : znacilke, 'oznake':oznake}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preuredi_besedilo(tekst):\n",
    "    '''\n",
    "    Metoda vrne prečiščen tekst\n",
    "    '''\n",
    "    tekst = tekst.lower()\n",
    "    tekst = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','', tekst)\n",
    "    tekst = re.sub('newline_token', '', tekst)\n",
    "    tekst = re.sub('newline', '', tekst)\n",
    "    tekst = re.sub('tokennewline', '', tekst)\n",
    "    tekst = re.sub('tab_token', '', tekst)\n",
    "    tekst = re.sub('``', '\"', tekst)\n",
    "    tekst = re.sub('`', '\\'', tekst)\n",
    "    tekst = re.sub('=', '', tekst)\n",
    "    tekst = re.sub('\\n', '', tekst)\n",
    "    tekst = re.sub(':', '', tekst)\n",
    "    tekst = re.sub('[\\s]+', ' ', tekst)\n",
    "    tekst = tekst.strip()\n",
    "    tekst = tekst.strip('\\'\"')\n",
    "    return tekst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bag_of_words(komentar, stopwords):    \n",
    "    '''\n",
    "    Metoda odstrani presledke, končnice in vrne posamezne besede. \n",
    "    Odstranimo nepotrebne whitespace in spremenimo v male črke\n",
    "    '''\n",
    "    komentar = preuredi_besedilo(komentar)\n",
    "    komentar = \" \".join(re.split(\"[^a-zA-Z]*\", komentar.lower())).strip()    \n",
    "    stemmer = PorterStemmer()\n",
    "    besede = [] \n",
    "    for beseda in komentar.split():\n",
    "        if not beseda in stopwords:\n",
    "            try:\n",
    "                besede.append(stemmer.stem(beseda))\n",
    "            except(IndexError):\n",
    "                besede.append(beseda)\n",
    "    return besede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2ngrams(text, n=3, exact=True):\n",
    "    '''\n",
    "    Vrne crkovne ngrame nad besedami\n",
    "    '''\n",
    "    return [\"\".join(j) for j in zip(*[text[i:] for i in range(n)])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram(komentar, min_n=1, max_n=3, stopwords=None, join=True):\n",
    "    '''\n",
    "    Metoda vrne max_n - min_n razlicnih tipove ngramov \n",
    "    '''\n",
    "    if min_n > max_n:\n",
    "        return get_ngram(komentar, max_n, min_n, stopwords, join)\n",
    "    cngrams = []\n",
    "    besede = ' '.join(get_bag_of_words(komentar, stopwords)).split()\n",
    "    for i in range(min_n, max_n + 1):\n",
    "        cngrams.append(ngrams(besede, i))\n",
    "    if join: \n",
    "        return [e for ngram in cngrams for e in list(ngram)]\n",
    "    else:\n",
    "        return cngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_words(tekst, algoritem, stopwords):\n",
    "    rdata = []\n",
    "    for comment in tekst:\n",
    "        comment = comment.split('\\t')\n",
    "        offens_type = int(comment[0])\n",
    "        comment = comment[1]\n",
    "        for e in algoritem(komentar=comment, stopwords=stopwords):\n",
    "            rdata.append(e)\n",
    "    return rdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_data(data, algoritem, stopwords, word_features, joinset=True):\n",
    "    x, y = [], []\n",
    "    for comment in data:\n",
    "        comment = comment.split('\\t')\n",
    "        offens_type = int(comment[0])\n",
    "        comment = comment[1]\n",
    "        tmp = {}\n",
    "        for e in algoritem(komentar=comment, stopwords=stopwords):\n",
    "            tmp[e] = (e in word_features)\n",
    "        x.append(tmp), y.append(offens_type)\n",
    "    if joinset:\n",
    "        out = []\n",
    "        for i in range(len(y)):\n",
    "            out.append((x[i], y[i]))\n",
    "        return out\n",
    "    else:\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_predict_data(data):\n",
    "    x = []\n",
    "    y = []\n",
    "    for e in data:\n",
    "        x.append(e[0])\n",
    "        y.append(e[1])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(tekst, test_tekst, features_proc, model, algoritem):\n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    all_words = []\n",
    "    for w in get_all_words(tekst, algoritem, stopwords):\n",
    "        all_words.append(w)\n",
    "    all_words = FreqDist(all_words)\n",
    "    word_features = list(all_words.keys())[:int(len(all_words) * features_proc)]\n",
    "    x = convert_data(tekst, algoritem, stopwords, word_features)\n",
    "    x_t, y_t = convert_data(test_tekst, algoritem, stopwords, word_features, False)\n",
    "    classifier = SklearnClassifier(model).train(x)\n",
    "    y_p = classifier.classify_many(x_t)\n",
    "    print(\"SVC_classifier accuracy percent:\",\n",
    "          (accuracy_score(y_t, y_p)))\n",
    "    print(classification_report(y_t, y_p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_SET_PER = 0.7\n",
    "CORP_SIZE = 1200\n",
    "\n",
    "def main():\n",
    "    datoteka = open('comments.txt', encoding=\"ISO-8859-1\")\n",
    "    tekst = datoteka.readlines()[1:CORP_SIZE + 1]\n",
    "    datoteka.close()    \n",
    "    shuffle(tekst)    \n",
    "    st_komentarjev = len(tekst)\n",
    "    deli = int(st_komentarjev * TRAIN_SET_PER)       \n",
    "    ucna_tekst = tekst[:deli]    \n",
    "    test_tekst = tekst[deli:st_komentarjev]    \n",
    "    run(ucna_tekst, test_tekst, 0.3, svm.SVC(), get_bag_of_words)\n",
    "    run(ucna_tekst, test_tekst, 0.3, svm.SVC(), get_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n",
      "/usr/lib/python3.6/site-packages/ipykernel/__main__.py:12: DeprecationWarning: generator 'ngrams' raised StopIteration\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
